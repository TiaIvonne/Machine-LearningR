---
title: "2_Bagging_RF"
output:
  html_document: default
  pdf_document: 
    latex_engine: xelatex
date: "2023-02-03"
lang: "es-ES"
urlcolor: blue
editor_options: 
  markdown: 
    wrap: 80
---

```{r include=FALSE, warning=FALSE}
load('myEnvironment.RData')
source("./src/functions/librerias.R")
knitr::opts_chunk$set(warning = FALSE) 
knitr::read_chunk("2_Bagging_RF.R")
```

\normalsize

## Bagging

### Tunning de bagging

En este apartado se probarán algunas técnicas para realizar tunning de bagging,
partiendo de un modelo "básico" utilizando las variables previamente
seleccionadas con stepwise y al final de este apartado realizando pruebas de
tunning sobre el tamaño muestral del dataset dengue.

Primer modelo de bagging con variables previamente seleccionadas:

\tiny

```{r chunk-bagging1, eval=FALSE, echo = TRUE}
```

```{r, eval= TRUE, echo=FALSE}
knitr::kable(bagging$results, "pipe")
```

\normalsize

A continuación se explora el Out of bag error para este modelo, buscando
parámetros para optimización, tal como lo indican los apuntes, se debe utilizar
la función de randomForest() para extraer los datos y presentar gráfico:

\tiny

```{r chunk-bagging2, eval=FALSE, echo = TRUE}
```

```{r, eval= TRUE, echo=FALSE, out.width="50%", fig.align='center'}
plot(baggingbis$err.rate[, 1], main = "Out of bag error", ylab = "error")
```

\normalsize

A partir de las 1000 muestras se estabiliza el error de los datos analizados

### Validación cruzada para bagging

Se realizan algunas pruebas con validación cruzada repetida utilizando la
función cruzadarfbin() y cuidando de incluir el parámetro mtry \tiny

```{r chunk-bagging3, eval=FALSE, echo = TRUE}
```

\normalsize

A continuación y a modo de complemento se prueba manipular el tamaño muestral
para observar el efecto sobre bagging utilizando el parámetro sampsize y aumentando los grupos de validación cruzada de 4 a 10, solo con fines de exploración.

\tiny

```{r chunk-bagging4, eval=FALSE, echo = TRUE}
```

\normalsize

Como parte de este complemento se evalúan las medias con la función
genera_gráficos() para comparar cual de todos estos tamaños muestrales entrega
mejores métricas:

\tiny

```{r chunk-bagging5, eval=TRUE, echo = TRUE, out.width="50%", fig.align='center',results='hide'}
```

\normalsize

**Observaciones**

-  Solo tomando en cuenta el gráfico, evidentemente las medias evaluadas con 10 grupos (base, 1000, 1250 y 1500) superan a los resultados obtenidos por el bagging original. Para efectos de comparación y decision de modelos se seguirá considerando solo *bagging*

### Comparacion de medias y boxplot

Utilizando la función genera_gráficos() se generan los gráficos para realizar
comparación de medias y evaluar los modelos
\tiny
```{r chunk-bagging6, eval=TRUE, echo = TRUE, out.width="50%", fig.align='center',results='hide'}
```
\normalsize
**Observaciones**

-  Los resultados mejoran utilizando bagging en relación a los modelos anteriores, 
menor varianza, mayor auc y menor tasa de fallos que los modelos anteriores.


## Random Forest Classifier

### Tunning de random forest

Primer modelo utilizando todas las variables y buscando las variables
predictoras mas relevantes. 
Nota: Solo como complemento a la práctica, para observar como se comporta el
algoritmo al seleccionar variables. Para comparar medias, validación cruzada y
probar con diferentes números de arboles se utilizan las variables seleccionadas
con *stepwise*

\tiny

```{r chunk-rf1, eval=FALSE, echo=TRUE}
```

\normalsize
Se obtienen los resultados de este primer modelo de randomforest

```{r chunk-rf1bis, out.width="50%", eval= TRUE, fig.align='center', echo=FALSE}
```

Para el modelo anterior el mejor mtry es 9 y en el gráfico se observa que las
variables predictoras mas relevantes serian: Xmax, h10pix, Ymax, trees90,
h10pix90, humid, Ymin lo cual difieren a los resultados entregados por la
selección *stepwise* pero con el fin de explorar las alternativas que ofrece el algoritmo
es útil.

\normalsize

A continuación se prueba generando un bucle for() para buscar los mejores
indicadores evaluando según el mtry y numero de trees, desde 300 a 2500 para
observar su comportamiento y buscar los mejores parámetros para la validación
cruzada:

\tiny

```{r chunk-rf2, eval=FALSE, echo=TRUE}
```

\tiny

```{r out.width="50%", fig.align='center'}
dotplot(results)
```

```{r}
fit$bestTune
```

\normalsize

El gráfico dotplot() muestra el accuracy correspondiente a los trees evaluados
en el ciclo for anterior, con esto los resultados en accuracy son similares pero
por complejidad se prefiere dejar para pruebas en 500 trees. Para el parámetro
*bestTune* el mtry es de 4 que también se dejara fijado en la validación
cruzada.

### Validacion cruzada para random forest

Se genera la validación cruzada para random forest utilizando la función
cruzadarfbin y los parámetros obtenidos del estudio anterior, con mtry= 4 y
ntree = 500

\tiny

```{r chunk-rf4, eval=FALSE, echo=TRUE}
```

\normalsize
### Comparacion de medias y boxplot

Utilizando la función genera_gráficos() se generan los gráficos para realizar
comparación de medias y evaluar los modelos
\tiny
```{r chunk-rf5, eval=TRUE, echo=TRUE, out.width="50%", fig.align='center', results='hide'}
```
\normalsize
**Observaciones**

-  De los algoritmos evaluados hasta el momento, randomforest y bagging son los 
que muestran mejor rendimiento en AUC y tasa de fallos, dejando atrás las 
regresiones logísticas y las redes neuronales.
